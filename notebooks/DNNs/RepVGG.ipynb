{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RepVGG\n",
    "\n",
    "<img src=\"https://i.ibb.co/wrxq7Kv/image.png\" alt=\"image\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterization\n",
    "\n",
    "Chứng minh kỹ thuật reparameterization, gọi đầu vào hình ảnh $X \\in \\mathbb{R}^{n \\times n}$ là một ma trận có dạng:\n",
    "\n",
    "$$ X = \n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{24} & x_{25} \\\\ \n",
    "x_{31} & x_{32} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{41} & x_{42} & x_{44} & x_{44} & x_{45} \\\\\n",
    "x_{51} & x_{52} & x_{55} & x_{55} & x_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "và ma trận trọng số $W$ thực hiện convolution:\n",
    "\n",
    "$$ W = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution (padding=$1$) $X * W$ là $Y$:\n",
    "\n",
    "$$ Y =\n",
    "\\begin{pmatrix}\n",
    "y_{11} & y_{12} & y_{13} & y_{14} & y_{15} \\\\\n",
    "y_{21} & y_{22} & y_{23} & y_{24} & y_{25} \\\\ \n",
    "y_{31} & y_{32} & y_{33} & y_{34} & y_{35} \\\\\n",
    "y_{41} & y_{42} & y_{44} & y_{44} & y_{45} \\\\\n",
    "y_{51} & y_{52} & y_{55} & y_{55} & y_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $y_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution pointwise với giá trị $p$ là $Z$:\n",
    "$$ Z =\n",
    "\\begin{pmatrix}\n",
    "z_{11} & z_{12} & z_{13} & z_{14} & z_{15} \\\\\n",
    "z_{21} & z_{22} & z_{23} & z_{24} & z_{25} \\\\ \n",
    "z_{31} & z_{32} & z_{33} & z_{34} & z_{35} \\\\\n",
    "z_{41} & z_{42} & z_{44} & z_{44} & z_{45} \\\\\n",
    "z_{51} & z_{52} & z_{55} & z_{55} & z_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $z_{22} = x_{22} \\times p$\n",
    "Vậy trong ma trận kết quả $K = Y + Z$ thì vị trí $K_{22} = y_{22} + z_{22} = (x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}) + (x_{22} \\times p)$\n",
    "\n",
    "\n",
    "Đây là operations diễn ra trong lúc train. Tuy nhiên khi inference thì ta áp dụng kỹ thuật reparameterization để giảm lượng params tính toán hay FLOPS bằng các bước sau:\n",
    "1. Padding giá trị $p$ thành ma trận trọng số $P$ có shape bằng ma trận $W$\n",
    "2. Tạo ma trận trọng số mởi là $E = W + E$\n",
    "3. Thực hiện phép convolution $X * E$ \n",
    "\n",
    "Lúc này ma trận được padded $P$ có dạng\n",
    "$$ P = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & p & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận trọng số mới $E$ có dạng:\n",
    "$$ E = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} + p & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận kết quả $K'$ có thành phần $K'_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + (w_{22} + p) \\times x_{22} + \\dots + x_{33} \\times w_{33} $. \\\n",
    "Chú ý phần tử $(w_{22} + p) \\times x_{22} = w_{22} \\times x_{22} + x_{22} \\times p$\n",
    "Từ đây ta dễ dàng so sánh và thấy $K = K'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0.7]\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "Y = F.conv2d(X, W, stride=1, padding=1)\n",
    "Z = F.conv2d(X, P, stride=1, padding=0)\n",
    "K = Y + Z\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0., 0., 0.],\n",
    "    [0., 0.7, 0.],\n",
    "    [0., 0., 0.],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "E = W + P\n",
    "\n",
    "K_ = F.conv2d(X, E, stride=1, padding=1)\n",
    "K_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How BatchNorm works\n",
    "\n",
    "Read more in this paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "Cho input $X \\in \\mathbb{R}^{B \\times C \\times H \\times W}$ với $B,C,H,W$ lần lượt là batch size, channels, height, width. Khi đưa qua BatchNorm, thì $\\text{BN}(X)$ được tính bằng cách: \\\\\n",
    "- Khởi tạo vector $\\mu$ (mean) và $v$ (variance) theo phân phối chuẩn:\n",
    "$$\n",
    "\\mu, v\\in \\mathbb{R}^C \\space | \\space  \\mu_i=0, v_i=1 \\space | \\space \\forall \\mu_i \\in \\mu, \\forall v_i \\in v\n",
    "$$\n",
    "\n",
    "- Sau đó $X$ sẽ được biến đối trong không gian bằng 2 phép $\\text{normalize}$ và $\\text{scale+shift}$\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - \\mu}{\\sqrt{v + \\epsilon}} \\\\\n",
    "X_{\\text{new}} = X_{\\text{norm}} \\gamma + \\beta\n",
    "$$\n",
    "\n",
    "- Trong đó epsilon $\\epsilon$ được khởi tạo $=1e^{-5}$ và $\\gamma, \\beta \\in R^C$ hay là vector shape là $(1, C, 1, 1)$. Hay từng feature $X_{\\text{new}}[:,i:,:]$ trong $X$ được tính:\n",
    "\n",
    "$$\n",
    "X^{\\text{new}}_{[:,i:,:]} =  \\frac{X_{[:,i,:,:]} - \\mu_i}{\\sqrt{v + \\epsilon}} \\gamma + \\beta_i\n",
    "$$\n",
    "\n",
    "## BatchNorm kết hợp Convolution\n",
    "Như ta đã biết, tổ hợp phổ biến trong computer vision là $\\text{Conv-Relu-BatchNorm}$. BatchNorm diễn ra sau Convolution (ví dụ bỏ qua ReLU) thì làm sao ta kết hợp bước Conv-BatchNorm trong lúc inference để tính toán nhanh hơn.  Gọi $X \\in \\mathbb{R}^{B, C_{in}, H, W}$ là ma trận đầu vào $W \\in \\mathbb{W}^{C_{out}, C_{in}, K, K}$ là ma trận trọng số để thực hiện phép convolution và ma trận kết quả là $Y = X * W + b \\space | \\space Y \\in \\mathbb{R}^{B, C_{out}, H', W'}$ với $*$ là phép convolution và $b$ là bias.\n",
    "\n",
    "$$\n",
    "\\text{BN}(Y, \\mu, v, \\gamma, \\beta) = (Y - \\mu) \\frac{\\gamma}{\\sqrt{v + \\epsilon}} + \\beta \\\\\n",
    "= (X * W + b - \\mu) \\frac{\\gamma}{\\sqrt{v + \\epsilon}}. \\\\\n",
    "= X * (W \\frac{\\gamma}{\\sqrt{v + \\epsilon}}) + \\frac{\\gamma}{\\sqrt{v + \\epsilon}} (b - \\mu) + \\beta\n",
    "= X * W' + b'\n",
    "$$\n",
    "\n",
    "Vậy ma trận trọng số mới là $W' = W \\frac{\\gamma}{\\sqrt{v + \\epsilon}}$ và bias mới là $b'= \\frac{\\gamma}{\\sqrt{v + \\epsilon}} (b - \\mu) + \\beta$. \\\\\n",
    "Nhưng ở đây ta cần phải lưu ý thêm về chiều khi nhần vào của $W'_{[i,:,:,:]} = \\frac{\\gamma_i}{\\sqrt{v_i + \\epsilon}} W_{[i,:,:,:]}$. Đây là lý do ta phải reshape các vector $\\gamma, v \\in (1, C_{out}, 1, 1)$ thành $(C_{out}), 1, 1, 1)$ trước khi nhân.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=0, momentum=0.1, training_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.training_mode = training_mode\n",
    "        self.momentum = 0.1\n",
    "        self.eps = eps\n",
    "\n",
    "        # trainable parameters\n",
    "        self.gamma = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n",
    "\n",
    "        # running mean & variance\n",
    "        self.r_mean = torch.zeros(1, num_features, 1, 1)\n",
    "        self.r_var = torch.ones(1, num_features, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training_mode:\n",
    "            x_mean = x.mean([0, 2, 3], keepdim=True)\n",
    "            x_var = x.var([0, 2, 3], keepdim=True, unbiased=False)\n",
    "\n",
    "            # Update running mean and variance\n",
    "            self.r_mean = (1 - self.momentum) * self.r_mean + self.momentum * x_mean\n",
    "            self.r_var = (1 - self.momentum) * self.r_var + self.momentum * x_var\n",
    "\n",
    "        else:\n",
    "            x_mean = self.r_mean\n",
    "            x_var = self.r_var\n",
    "\n",
    "        x_norm = (x - x_mean) / torch.sqrt(x_var + self.eps)         # Normalize\n",
    "        x_out = x_norm * self.gamma + self.beta                      # Scale and Shift\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo ma trận X, trọng số W và bias b\n",
    "X = torch.randn(12, 32, 224, 224)\n",
    "W = torch.randn(64, 32, 3, 3)\n",
    "b = torch.randn(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution bình thường\n",
    "Y = F.conv2d(X, W, b, stride=1, padding=1)\n",
    "bn = BatchNorm(64)\n",
    "Z = bn(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape trước khi nhân\n",
    "gamma = bn.gamma.view(64, 1, 1, 1)\n",
    "var = bn.r_var.view(64, 1, 1, 1)\n",
    "mean = bn.r_mean.view(64, 1, 1, 1)\n",
    "beta = bn.beta.view(64, 1, 1, 1)\n",
    "eps = bn.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization\n",
    "W_ = W * (gamma / torch.sqrt(var + eps))\n",
    "b_ = (gamma / torch.sqrt(var + eps)) * (b.view(64, 1, 1, 1) - mean) + beta\n",
    "b_ = b_.squeeze()\n",
    "\n",
    "Z_ = F.conv2d(X, W_, b_, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.7985, grad_fn=<SelectBackward0>)\n",
      "tensor(18.7985, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra\n",
    "print(Z[2,10,56,56])\n",
    "print(Z_[2,10,56,56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "    result = nn.Sequential()\n",
    "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
    "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
    "    return result\n",
    "\n",
    "class RepVGGBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n",
    "        super(RepVGGBlock, self).__init__()\n",
    "        self.deploy = deploy\n",
    "        self.groups = groups\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        assert kernel_size == 3\n",
    "        assert padding == 1\n",
    "\n",
    "        padding_11 = padding - kernel_size // 2\n",
    "\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "\n",
    "        if use_se:\n",
    "            #   Note that RepVGG-D2se uses SE before nonlinearity. But RepVGGplus models uses SE after nonlinearity.\n",
    "            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
    "        else:\n",
    "            self.se = nn.Identity()\n",
    "\n",
    "        if deploy:\n",
    "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
    "\n",
    "        else:\n",
    "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
    "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
    "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n",
    "\n",
    "        if self.rbr_identity is None:\n",
    "            id_out = 0\n",
    "        else:\n",
    "            id_out = self.rbr_identity(inputs)\n",
    "\n",
    "        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n",
    "\n",
    "\n",
    "    #   Optional. This may improve the accuracy and facilitates quantization in some cases.\n",
    "    #   1.  Cancel the original weight decay on rbr_dense.conv.weight and rbr_1x1.conv.weight.\n",
    "    #   2.  Use like this.\n",
    "    #       loss = criterion(....)\n",
    "    #       for every RepVGGBlock blk:\n",
    "    #           loss += weight_decay_coefficient * 0.5 * blk.get_cust_L2()\n",
    "    #       optimizer.zero_grad()\n",
    "    #       loss.backward()\n",
    "    def get_custom_L2(self):\n",
    "        K3 = self.rbr_dense.conv.weight\n",
    "        K1 = self.rbr_1x1.conv.weight\n",
    "        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
    "        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
    "\n",
    "        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()      # The L2 loss of the \"circle\" of weights in 3x3 kernel. Use regular L2 on them.\n",
    "        eq_kernel = K3[:, :, 1:2, 1:2] * t3 + K1 * t1                           # The equivalent resultant central point of 3x3 kernel.\n",
    "        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()        # Normalize for an L2 coefficient comparable to regular L2.\n",
    "        return l2_loss_eq_kernel + l2_loss_circle\n",
    "\n",
    "\n",
    "\n",
    "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
    "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
    "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
    "#   May be useful for quantization or pruning.\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        if isinstance(branch, nn.Sequential):\n",
    "            kernel = branch.conv.weight\n",
    "            running_mean = branch.bn.running_mean\n",
    "            running_var = branch.bn.running_var\n",
    "            gamma = branch.bn.weight\n",
    "            beta = branch.bn.bias\n",
    "            eps = branch.bn.eps\n",
    "        else:\n",
    "            assert isinstance(branch, nn.BatchNorm2d)\n",
    "            if not hasattr(self, 'id_tensor'):\n",
    "                input_dim = self.in_channels // self.groups\n",
    "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
    "                for i in range(self.in_channels):\n",
    "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
    "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
    "            kernel = self.id_tensor\n",
    "            running_mean = branch.running_mean\n",
    "            running_var = branch.running_var\n",
    "            gamma = branch.weight\n",
    "            beta = branch.bias\n",
    "            eps = branch.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "    def switch_to_deploy(self):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n",
    "                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n",
    "                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n",
    "        self.rbr_reparam.weight.data = kernel\n",
    "        self.rbr_reparam.bias.data = bias\n",
    "        self.__delattr__('rbr_dense')\n",
    "        self.__delattr__('rbr_1x1')\n",
    "        if hasattr(self, 'rbr_identity'):\n",
    "            self.__delattr__('rbr_identity')\n",
    "        if hasattr(self, 'id_tensor'):\n",
    "            self.__delattr__('id_tensor')\n",
    "        self.deploy = True\n",
    "\n",
    "\n",
    "\n",
    "class RepVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False, use_checkpoint=False):\n",
    "        super(RepVGG, self).__init__()\n",
    "        assert len(width_multiplier) == 4\n",
    "        self.deploy = deploy\n",
    "        self.override_groups_map = override_groups_map or dict()\n",
    "        assert 0 not in self.override_groups_map\n",
    "        self.use_se = use_se\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
    "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_se=self.use_se)\n",
    "        self.cur_layer_idx = 1\n",
    "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
    "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
    "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
    "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
    "\n",
    "    def _make_stage(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
    "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
    "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n",
    "            self.in_planes = planes\n",
    "            self.cur_layer_idx += 1\n",
    "        return nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stage0(x)\n",
    "        for stage in (self.stage1, self.stage2, self.stage3, self.stage4):\n",
    "            for block in stage:\n",
    "                if self.use_checkpoint:\n",
    "                    out = checkpoint.checkpoint(block, out)\n",
    "                else:\n",
    "                    out = block(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
