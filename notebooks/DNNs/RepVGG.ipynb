{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RepVGG\n",
    "\n",
    "<img src=\"https://i.ibb.co/wrxq7Kv/image.png\" alt=\"image\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterization\n",
    "\n",
    "Chứng minh kỹ thuật reparameterization, gọi đầu vào hình ảnh $X \\in \\mathbb{R}^{n \\times n}$ là một ma trận có dạng:\n",
    "\n",
    "$$ X = \n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{24} & x_{25} \\\\ \n",
    "x_{31} & x_{32} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{41} & x_{42} & x_{44} & x_{44} & x_{45} \\\\\n",
    "x_{51} & x_{52} & x_{55} & x_{55} & x_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "và ma trận trọng số $W$ thực hiện convolution:\n",
    "\n",
    "$$ W = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution (padding=$1$) $X * W$ là $Y$:\n",
    "\n",
    "$$ Y =\n",
    "\\begin{pmatrix}\n",
    "y_{11} & y_{12} & y_{13} & y_{14} & y_{15} \\\\\n",
    "y_{21} & y_{22} & y_{23} & y_{24} & y_{25} \\\\ \n",
    "y_{31} & y_{32} & y_{33} & y_{34} & y_{35} \\\\\n",
    "y_{41} & y_{42} & y_{44} & y_{44} & y_{45} \\\\\n",
    "y_{51} & y_{52} & y_{55} & y_{55} & y_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $y_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution pointwise với giá trị $p$ là $Z$:\n",
    "$$ Z =\n",
    "\\begin{pmatrix}\n",
    "z_{11} & z_{12} & z_{13} & z_{14} & z_{15} \\\\\n",
    "z_{21} & z_{22} & z_{23} & z_{24} & z_{25} \\\\ \n",
    "z_{31} & z_{32} & z_{33} & z_{34} & z_{35} \\\\\n",
    "z_{41} & z_{42} & z_{44} & z_{44} & z_{45} \\\\\n",
    "z_{51} & z_{52} & z_{55} & z_{55} & z_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $z_{22} = x_{22} \\times p$\n",
    "Vậy trong ma trận kết quả $K = Y + Z$ thì vị trí $K_{22} = y_{22} + z_{22} = (x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}) + (x_{22} \\times p)$\n",
    "\n",
    "\n",
    "Đây là operations diễn ra trong lúc train. Tuy nhiên khi inference thì ta áp dụng kỹ thuật reparameterization để giảm lượng params tính toán hay FLOPS bằng các bước sau:\n",
    "1. Padding giá trị $p$ thành ma trận trọng số $P$ có shape bằng ma trận $W$\n",
    "2. Tạo ma trận trọng số mởi là $E = W + E$\n",
    "3. Thực hiện phép convolution $X * E$ \n",
    "\n",
    "Lúc này ma trận được padded $P$ có dạng\n",
    "$$ P = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & p & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận trọng số mới $E$ có dạng:\n",
    "$$ E = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} + p & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận kết quả $K'$ có thành phần $K'_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + (w_{22} + p) \\times x_{22} + \\dots + x_{33} \\times w_{33} $. \\\n",
    "Chú ý phần tử $(w_{22} + p) \\times x_{22} = w_{22} \\times x_{22} + x_{22} \\times p$\n",
    "Từ đây ta dễ dàng so sánh và thấy $K = K'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0.7]\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "Y = F.conv2d(X, W, stride=1, padding=1)\n",
    "Z = F.conv2d(X, P, stride=1, padding=0)\n",
    "K = Y + Z\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0., 0., 0.],\n",
    "    [0., 0.7, 0.],\n",
    "    [0., 0., 0.],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "E = W + P\n",
    "\n",
    "K_ = F.conv2d(X, E, stride=1, padding=1)\n",
    "K_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparam BatchNorm\n",
    "\n",
    "Cho một ma trận $M \\in R^{n \\times n}$, thì $\\text{BN}(M)$ được tính bằng cách:\n",
    "\n",
    "- Tính giá trị trung bình $\\mu$:\n",
    "$$ \\mu = \\frac{1}{m} \\sum_{i=1}^m M_i $$\n",
    "\n",
    "- Sau đó tính độ bình phương độ lệch chuẩn $\\sigma^2$:\n",
    "$$ \\sigma^2 = \\frac{1}{m} \\sum_{i=1}^m (M_i - \\mu)^2 $$\n",
    "\n",
    "- Sau đó thực hiện normalization:\n",
    "$$ \\hat{M} = \\frac{M - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} $$\n",
    "\n",
    "- Sau đó ta có thể Scale (biến đổi) và Shift/Transalte (dịch chuyển) ma trận này bằng cách:\n",
    "$$ bn(M, \\mu, \\sigma, \\gamma, \\beta) = \\gamma \\hat{M} + \\beta $$ \n",
    "\n",
    "$$ bn(M, \\mu, \\sigma, \\gamma, \\beta) = \\gamma \\frac{M - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta $$\n",
    "\n",
    "với $\\mu, \\sigma, \\gamma, \\beta$ là các giá trị cho trước. Giả sử $\\epsilon=0$ thì ta có thể viết đơn giản lại thành:\n",
    "\n",
    "$$ bn(M, \\mu, \\sigma, \\gamma, \\beta) = (M - \\mu) \\frac{\\gamma}{\\sigma} + \\beta $$\n",
    "\n",
    "Vậy nếu ta lấy Batch Norm của ma trận là kết quả phép convolution $M * W$ thì có dạng:\n",
    "\n",
    "$$ bn(M * W, \\mu, \\sigma, \\gamma, \\beta) = (M * W - \\mu) \\frac{\\gamma}{\\sigma} + \\beta $$\n",
    "$$= M * (W \\frac{\\gamma}{\\sigma}) + (- \\mu \\frac{\\gamma}{\\sigma} + \\beta) $$\n",
    "\n",
    "Biểu thức sẽ cho ta ma trận trọng số mới $W' = W \\frac{\\gamma}{\\sigma}$ và bias mới $b = - \\mu \\frac{\\gamma}{\\sigma} + \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How BatchNorm works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "    result = nn.Sequential()\n",
    "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
    "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
    "    return result\n",
    "\n",
    "class RepVGGBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n",
    "        super(RepVGGBlock, self).__init__()\n",
    "        self.deploy = deploy\n",
    "        self.groups = groups\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        assert kernel_size == 3\n",
    "        assert padding == 1\n",
    "\n",
    "        padding_11 = padding - kernel_size // 2\n",
    "\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "\n",
    "        if use_se:\n",
    "            #   Note that RepVGG-D2se uses SE before nonlinearity. But RepVGGplus models uses SE after nonlinearity.\n",
    "            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
    "        else:\n",
    "            self.se = nn.Identity()\n",
    "\n",
    "        if deploy:\n",
    "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
    "\n",
    "        else:\n",
    "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
    "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
    "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n",
    "\n",
    "        if self.rbr_identity is None:\n",
    "            id_out = 0\n",
    "        else:\n",
    "            id_out = self.rbr_identity(inputs)\n",
    "\n",
    "        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n",
    "\n",
    "\n",
    "    #   Optional. This may improve the accuracy and facilitates quantization in some cases.\n",
    "    #   1.  Cancel the original weight decay on rbr_dense.conv.weight and rbr_1x1.conv.weight.\n",
    "    #   2.  Use like this.\n",
    "    #       loss = criterion(....)\n",
    "    #       for every RepVGGBlock blk:\n",
    "    #           loss += weight_decay_coefficient * 0.5 * blk.get_cust_L2()\n",
    "    #       optimizer.zero_grad()\n",
    "    #       loss.backward()\n",
    "    def get_custom_L2(self):\n",
    "        K3 = self.rbr_dense.conv.weight\n",
    "        K1 = self.rbr_1x1.conv.weight\n",
    "        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
    "        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n",
    "\n",
    "        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()      # The L2 loss of the \"circle\" of weights in 3x3 kernel. Use regular L2 on them.\n",
    "        eq_kernel = K3[:, :, 1:2, 1:2] * t3 + K1 * t1                           # The equivalent resultant central point of 3x3 kernel.\n",
    "        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()        # Normalize for an L2 coefficient comparable to regular L2.\n",
    "        return l2_loss_eq_kernel + l2_loss_circle\n",
    "\n",
    "\n",
    "\n",
    "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
    "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
    "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
    "#   May be useful for quantization or pruning.\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        if isinstance(branch, nn.Sequential):\n",
    "            kernel = branch.conv.weight\n",
    "            running_mean = branch.bn.running_mean\n",
    "            running_var = branch.bn.running_var\n",
    "            gamma = branch.bn.weight\n",
    "            beta = branch.bn.bias\n",
    "            eps = branch.bn.eps\n",
    "        else:\n",
    "            assert isinstance(branch, nn.BatchNorm2d)\n",
    "            if not hasattr(self, 'id_tensor'):\n",
    "                input_dim = self.in_channels // self.groups\n",
    "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
    "                for i in range(self.in_channels):\n",
    "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
    "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
    "            kernel = self.id_tensor\n",
    "            running_mean = branch.running_mean\n",
    "            running_var = branch.running_var\n",
    "            gamma = branch.weight\n",
    "            beta = branch.bias\n",
    "            eps = branch.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "    def switch_to_deploy(self):\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n",
    "                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n",
    "                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n",
    "        self.rbr_reparam.weight.data = kernel\n",
    "        self.rbr_reparam.bias.data = bias\n",
    "        self.__delattr__('rbr_dense')\n",
    "        self.__delattr__('rbr_1x1')\n",
    "        if hasattr(self, 'rbr_identity'):\n",
    "            self.__delattr__('rbr_identity')\n",
    "        if hasattr(self, 'id_tensor'):\n",
    "            self.__delattr__('id_tensor')\n",
    "        self.deploy = True\n",
    "\n",
    "\n",
    "\n",
    "class RepVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False, use_checkpoint=False):\n",
    "        super(RepVGG, self).__init__()\n",
    "        assert len(width_multiplier) == 4\n",
    "        self.deploy = deploy\n",
    "        self.override_groups_map = override_groups_map or dict()\n",
    "        assert 0 not in self.override_groups_map\n",
    "        self.use_se = use_se\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
    "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_se=self.use_se)\n",
    "        self.cur_layer_idx = 1\n",
    "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
    "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
    "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
    "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
    "\n",
    "    def _make_stage(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
    "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
    "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n",
    "            self.in_planes = planes\n",
    "            self.cur_layer_idx += 1\n",
    "        return nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stage0(x)\n",
    "        for stage in (self.stage1, self.stage2, self.stage3, self.stage4):\n",
    "            for block in stage:\n",
    "                if self.use_checkpoint:\n",
    "                    out = checkpoint.checkpoint(block, out)\n",
    "                else:\n",
    "                    out = block(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
