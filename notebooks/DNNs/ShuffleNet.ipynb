{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleNet\n",
    "The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy.\n",
    "\n",
    "<img src=\"https://i.ibb.co/3sCBhBP/image.png\" alt=\"image\" border=\"0\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1,\n",
    "            padding=1, bias=True, groups=1):\n",
    "    \"\"\"3x3 convolution with padding \"\"\"\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=padding,\n",
    "                     bias=bias,\n",
    "                     groups=groups)\n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    \"\"\"1x1 convolution with padding\n",
    "    - Normal pointwise convolution When groups == 1\n",
    "    - Grouped pointwise convolution when groups > 1\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size=1,\n",
    "                     groups=groups,\n",
    "                     stride=1)\n",
    "\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, channels_per_group, height, width)\n",
    "\n",
    "    # transpose\n",
    "    # - contiguous() required if transpose() is used before view().\n",
    "    #   See https://github.com/pytorch/pytorch/issues/764\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "    return x\n",
    "\n",
    "\n",
    "class ShuffleUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, groups=3,\n",
    "                 grouped_conv=True, combine='add'):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.grouped_conv = grouped_conv\n",
    "        self.combine = combine\n",
    "        self.groups = groups\n",
    "        self.bottleneck_channels = self.out_channels // 4\n",
    "\n",
    "        # Define the type of ShuffleUnit\n",
    "        if self.combine == 'add':\n",
    "            # ShuffleUnit Figure 2b\n",
    "            self.depthwise_stride = 1\n",
    "            self._combine_func = self._add\n",
    "\n",
    "        elif self.combine == 'concat':\n",
    "            # ShuffleUnit Figure 2c\n",
    "            self.depthwise_stride = 2\n",
    "            self._combine_func = self._concat\n",
    "            self.out_channels -= self.in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Cannot combine tensors with \\\"{}\\\"\" \\\n",
    "                             \"Only \\\"add\\\" and \\\"concat\\\" are\" \\\n",
    "                             \"supported\".format(self.combine))\n",
    "\n",
    "        # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n",
    "        # to bottleneck channels, as in a ResNet bottleneck module.\n",
    "        # NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\n",
    "        self.first_1x1_groups = self.groups if grouped_conv else 1\n",
    "\n",
    "        self.g_conv_1x1_compress = self._make_grouped_conv1x1(\n",
    "            self.in_channels,\n",
    "            self.bottleneck_channels,\n",
    "            self.first_1x1_groups,\n",
    "            batch_norm=True,\n",
    "            relu=True\n",
    "        )\n",
    "\n",
    "        # 3x3 depthwise convolution followed by batch normalization\n",
    "        self.depthwise_conv3x3 = conv3x3(\n",
    "            self.bottleneck_channels, self.bottleneck_channels,\n",
    "            stride=self.depthwise_stride, groups=self.bottleneck_channels\n",
    "        )\n",
    "        self.bn_after_depthwise = nn.BatchNorm2d(self.bottleneck_channels)\n",
    "\n",
    "        # Use 1x1 grouped convolution to expand from bottleneck_channels to out_channels\n",
    "        self.g_conv_1x1_expand = self._make_grouped_conv1x1(\n",
    "            self.bottleneck_channels,\n",
    "            self.out_channels,\n",
    "            self.groups,\n",
    "            batch_norm=True,\n",
    "            relu=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _add(x, out):\n",
    "        # residual connection\n",
    "        return x + out\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, out):\n",
    "        # concatenate along channel axis\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "    def _make_grouped_conv1x1(self, in_channels, out_channels, groups,\n",
    "                              batch_norm=True, relu=False):\n",
    "        modules = OrderedDict()\n",
    "        conv = conv1x1(in_channels, out_channels, groups=groups)\n",
    "        modules['conv1x1'] = conv\n",
    "\n",
    "        if batch_norm:\n",
    "            modules['batch_norm'] = nn.BatchNorm2d(out_channels)\n",
    "        if relu:\n",
    "            modules['relu'] = nn.ReLU()\n",
    "        if len(modules) > 1:\n",
    "            return nn.Sequential(modules)\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        if self.combine == 'concat':\n",
    "            residual = F.avg_pool2d(residual, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        out = self.g_conv_1x1_compress(x)\n",
    "        out = channel_shuffle(out, self.groups)\n",
    "        out = self.depthwise_conv3x3(out)\n",
    "        out = self.bn_after_depthwise(out)\n",
    "        out = self.g_conv_1x1_expand(out)\n",
    "        out = self._combine_func(residual, out)\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/QCfc6kr/image.png\" alt=\"image\" border=\"0\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ShuffleNet(nn.Module):\n",
    "    def __init__(self, groups=3, in_channels=3, num_classes=1000):\n",
    "        \"\"\"\n",
    "        ShuffleNet constructor.\n",
    "        Arguments:\n",
    "            groups (int, optional): number of groups to be used in grouped\n",
    "                1x1 convolutions in each ShuffleUnit. Default is 3 for best\n",
    "                performance according to original paper.\n",
    "            in_channels (int, optional): number of channels in the input tensor.\n",
    "                Default is 3 for RGB image inputs.\n",
    "            num_classes (int, optional): number of classes to predict. Default\n",
    "                is 1000 for ImageNet.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.groups = groups\n",
    "        self.stage_repeats = [3, 7, 3]\n",
    "        self.in_channels =  in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if groups == 1:\n",
    "            self.stage_out_channels = [-1, 24, 144, 288, 567]\n",
    "        elif groups == 2:\n",
    "            self.stage_out_channels = [-1, 24, 200, 400, 800]\n",
    "        elif groups == 3:\n",
    "            self.stage_out_channels = [-1, 24, 240, 480, 960]\n",
    "        elif groups == 4:\n",
    "            self.stage_out_channels = [-1, 24, 272, 544, 1088]\n",
    "        elif groups == 8:\n",
    "            self.stage_out_channels = [-1, 24, 384, 768, 1536]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"\"\"{} groups is not supported for\n",
    "                   1x1 Grouped Convolutions\"\"\".format(groups))\n",
    "\n",
    "        # Stage 1 always has 24 output channels\n",
    "        self.conv1 = conv3x3(self.in_channels, self.stage_out_channels[1], stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Stage 2-3-4\n",
    "        self.stage2 = self._make_stage(2)\n",
    "        self.stage3 = self._make_stage(3)\n",
    "        self.stage4 = self._make_stage(4)\n",
    "\n",
    "        # Fully-connected classification layer\n",
    "        num_inputs = self.stage_out_channels[-1]\n",
    "        self.fc = nn.Linear(num_inputs, self.num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_stage(self, stage):\n",
    "        modules = OrderedDict()\n",
    "        stage_name = \"ShuffleUnit_Stage{}\".format(stage)\n",
    "\n",
    "        \"\"\"\n",
    "        First ShuffleUnit in the stage\n",
    "        1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n",
    "           is used in Stage 2. Group convolutions used everywhere else. \"\"\"\n",
    "\n",
    "        grouped_conv = stage > 2\n",
    "\n",
    "        # 2. concatenation unit is always used.\n",
    "        first_module = ShuffleUnit(\n",
    "            self.stage_out_channels[stage-1],\n",
    "            self.stage_out_channels[stage],\n",
    "            groups=self.groups,\n",
    "            grouped_conv=grouped_conv,\n",
    "            combine='concat'\n",
    "        )\n",
    "        modules[stage_name+\"_0\"] = first_module\n",
    "\n",
    "        # add more ShuffleUnits depending on pre-defined number of repeats\n",
    "        for i in range(self.stage_repeats[stage-2]):\n",
    "            name = stage_name + \"_{}\".format(i+1)\n",
    "            module = ShuffleUnit(\n",
    "                self.stage_out_channels[stage],\n",
    "                self.stage_out_channels[stage],\n",
    "                groups=self.groups,\n",
    "                grouped_conv=True,\n",
    "                combine='add'\n",
    "            )\n",
    "            modules[name] = module\n",
    "        return nn.Sequential(modules)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stage 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Other stage\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        # Output\n",
    "        x = F.avg_pool2d(x, x.data.size()[-2:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input = torch.rand(3, 3, 224, 224)\n",
    "model = ShuffleNet()\n",
    "output = model(input)\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
