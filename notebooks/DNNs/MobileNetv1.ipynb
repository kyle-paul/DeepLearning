{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperable Convolution\n",
    "\n",
    "<img src=\"https://i.ibb.co/4scJtB9/image.png\" alt=\"image\" border=\"0\">\n",
    "\n",
    "Input feature maps $X$: $D_{in} \\times D_{in} \\times C_{in}$, 1 convolution kernel: $D_k \\times D_k \\times C_{in} \\rightarrow$ output feature maps $G$: $D_{out} \\times D_{out} \\times N$. So the cost:\n",
    "- Mults once: $D_K^2 \\times C_{in}$\n",
    "- Mults per conv kernel: $D_K^2 \\times C_{in} \\times D_{out}^2$\n",
    "- Mults $C_{out}$ kernels: $D_K^2 \\times C_{in} \\times D_{out}^2 \\times C_{out} \\space (2)$\n",
    "\n",
    "Depthwise Convolution: Filtering stage + Pointwise ConvolutionL Combining stage.\n",
    "- Instead of using $D_{in} \\times D_{in} \\times C_{in}$, we use $M$ kernels $D_{in} \\times D_{in} \\times 1$. With each this kernel, we end up having $D_{out} \\times D_{out} \\times 1$, so stacking $M$ this output, we get $D_{out} \\times D_{out} \\times C_{in}$. So we have the cost: $D_K^2 \\times D_{out}^2 \\times C_{in}$\n",
    "- We use $C_{out}$ convs $1 \\times 1 \\times C_{in}$, so we end up changing the channel size from $C_{in}$ to $C_{out}$. So we have the cost: $C_{in} \\times D_{out}^2 \\times C_{out}$\n",
    "- Total cost is: $D_K^2 \\times D_{out}^2 \\times M + M \\times D_{out}^2 \\times N = M \\times D_{out}^2 \\times (D_K^2 + C_{out}) \\space (1)$\n",
    "\n",
    "So finally, we take:\n",
    "$$(1) / (2) = \\frac{D_K^2 + C_{out}}{D_K^2 \\times C_{out}} = \\frac{1}{C_{out}} + \\frac{1}{D_K^2}$$\n",
    "\n",
    "If $N=1024$ and $D_K=3$ (common), we get: $$\\frac{1}{1024} + \\frac{1}{9} = 0.112$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardConv(nn.Module):\n",
    "  def __init__(self, C_in, C_out, K):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=K, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)\n",
    "\n",
    "class SeperableConv(nn.Module):\n",
    "  def __init__(self, C_in, C_out, K):\n",
    "    super().__init__()\n",
    "    self.depthwise = nn.Conv2d(in_channels=C_in, out_channels=C_in, kernel_size=K, groups=C_in, stride=2, padding=1)\n",
    "    self.pointwise = nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.depthwise(x)\n",
    "    x = self.pointwise(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 64, 64]) torch.Size([1, 1024, 64, 64])\n",
      "19331547136 4719616\n",
      "2172649472 530432\n",
      "Params: 0.11238880451290953\n",
      "FLOP: 0.11238880451290953\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 512, 128, 128)\n",
    "\n",
    "standard_conv = StandardConv(C_in=512, C_out=1024, K=3)\n",
    "standard_x = standard_conv(x)\n",
    "\n",
    "seperable_conv = SeperableConv(C_in=512, C_out=1024, K=3)\n",
    "sep_x = seperable_conv(x)\n",
    "\n",
    "print(standard_x.shape, sep_x.shape)\n",
    "\n",
    "output = torchinfo.summary(standard_conv, x.shape)\n",
    "print(output.total_mult_adds, output.total_params)\n",
    "\n",
    "output_sep = torchinfo.summary(seperable_conv, x.shape)\n",
    "print(output_sep.total_mult_adds, output_sep.total_params)\n",
    "\n",
    "print(f\"Params: {output_sep.total_params / output.total_params}\")\n",
    "print(f\"FLOP: {output_sep.total_mult_adds / output.total_mult_adds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Cost Access (MCA)\n",
    "- Memoy Cost Access refers to the time and energy required to read from or write to memory in a computing system.\n",
    "- This cost vary depending on several factors: type of memory (e.g, cache, DRAM, or SSD), the location of data (e.g, on-chip or off-chip), and the access pattern (e.g., sequential or random access).\n",
    "- Branching cause increased uintermediate data: each branch typically produces intermediate data that needs to be stored and accessed. This increases the amount of memory used and the frequency of memory accesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
